---
layout: page
permalink: /Others/
title: Others
description: 
nav: true
nav_order: 6
---


<head>
<style>
h3 {
  display: block;
  font-size: 1.17em;
  margin-top: 1em;
  margin-bottom: 1em;
  margin-left: 0;
  margin-right: 0;
  font-weight: bold;
}
</style>
</head>


<h3>Academic Services</h3>
<div>
    <ul>
        <li>Conference Reviewer of CVPR, ICCV, ECCV, ICLR, NeurIPS, ICML, SIGGRAPH Asia, AAAI</li>
        <li>Journal Reviewer of IJCV, TMM, TIP</li>
    </ul>    
</div>


<h3>Workshops and Challenges</h3>
<div>
    <ul>
        <li>Organizer of <a href="https://competitions.codalab.org/competitions/25228">DeeperForensics Challenge on Real-World Face Forgery Detection</a>, ECCV 2020</li>
        <li>Organizer of <a href="https://sense-human.github.io/">Workshop on Sensing, Understanding and Synthesizing Humans</a>, ECCV 2020</li>
        <li>Organizer of <a href="https://openaccess.thecvf.com/ICCV2019_workshops/ICCV2019_SDL-CV">Workshop on Statistical Deep Learning for Computer Vision</a>, ICCV 2019</li>
    </ul>    
</div>

<h3>Teaching</h3>
<div>
    <ul>
        <li>Co-Instructor, Advanced Computer Vision, Tsinghua University, Spring 2023</li>
        <li>Teaching Assitant, Numerical Analysis, Tsinghua University, Spring 2018</li>
        <li>Teaching Assitant, Combinatorial Mathematics, Tsinghua University, Spring 2016</li>
    </ul>
</div>


<h3>Selected Honors</h3>
<div>
    <ul>
        <li>Best Paper Candidate at CVPR, 2023</li>
		<li>Champion, Pre-training for Video Understanding Challenge at MultiMedia, 2022</li>
        <li>Outstanding Project Award at SenseTime Research, 2022</li>
        <li>Outstanding Team Award at SenseTime Research (Company Listing Team & Digital Human Team), 2021</li>
		<li>Future Star Award at SenseTime Research, 2018</li>
        <li>First Runner-up, Webvision Challenge at CVPR, 2018</li>
		<li>Excellent Undergraduate of Beijing City, 2015</li>
		<li>Student Outstanding Undergraduate Thesis, 2015</li>
		<li>National Scholarship (top 1%), 2014</li>
    </ul>
</div>




<h3>Selected Publicity</h3>
<div>
    <ul>
        <li>Weights & Biases: <a href="https://wandb.ai/telidavies/ml-news/reports/StyleGAN-Human-More-Accurate-Generation-Of-Full-Body-Humans--VmlldzoxODgxOTky">StyleGAN-Human: More Accurate Generation of Full-Body Humans.</a> 2022</li>
        <li>MarkTechPost: <a href="https://www.marktechpost.com/2022/05/02/researchers-sensetime-develop-gnr-generalizable-neural-performer-for-human-novel-view-synthesis/">Researchers Develop the Generalizable Neural Performer for Human Novel View Synthesis.</a> 2022</li>
		<li>VentureBeat: <a href="https://venturebeat.com/2020/01/17/sensetimes-ai-generates-realistic-deepfake-videos/">SenseTime’s AI Generates Realistic DeepFake Videos.</a> 2020</li>
		<li>Synced: <a href="https://medium.com/syncedreview/nlpr-sensetime-ntu-accelerate-automatic-video-portrait-editing-f355ef2bf53f">NLPR, SenseTime & NTU Accelerate Automatic Video Portrait Editing.</a> 2020</li>
		<li>Vice: <a href="https://www.vice.com/en/article/g5xvk7/researchers-created-a-way-to-make-realistic-deepfakes-from-audio-clips">New Deepfake Method Can Put Words In Anyone’s Mouth.</a> 2020</li>
		<li>DIW: <a href="https://www.digitalinformationworld.com/2020/01/latest-deepfake-technology-create-more-convincing-videos-based-on-audio-source-than-ever-before.html">Latest Deepfake Technology Create More Convincing Videos Based on Audio Than Ever Before.</a> 2020</li>
		<li>QBitAI: <a href="https://www.qbitai.com/2020/01/10911.html">SenseTime Join in the Suppression of DeepFake with World’s Largest Forgery Detection Dataset.</a> 2020</li>
		<li>VentureBeat: <a href="https://venturebeat.com/2020/01/15/sensetime-face-forgery-research-deepfakes/">SenseTime Researchers Create a Benchmark to Test Face Forgery Detectors.</a> 2020</li>
    </ul>    
</div>


















